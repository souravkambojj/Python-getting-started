{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from cvloop import cvloop\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import matrix\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize_video(video):\n",
    "    vidcap= cv2.VideoCapture(video)\n",
    "    print(\"Frames Rate: %f frames/second\"%vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    print(\"Frame Count: %d frames\"%int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "    vidcap.set(cv2.CAP_PROP_POS_AVI_RATIO,1)\n",
    "    duration=int(vidcap.get(cv2.CAP_PROP_POS_MSEC)/1000)\n",
    "    print(\"Video Duration: %d seconds\"%duration)\n",
    "    width = vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float\n",
    "    height = vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    print(\"width,height :\",int(width),\"X\",int(height))\n",
    "\n",
    "def get_frames(video_path):  \n",
    "    cap= cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()  \n",
    "        if ret==True:\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    return frames \n",
    "\n",
    "def check_identity(all_frames,known_frame,frame_rate=30):\n",
    "    known_encoding=face_recognition.face_encodings(cv2.imread(known_frame))[0]\n",
    "    unknown_encodings=[face_recognition.face_encodings(frame)[0] for frame in all_frames]\n",
    "    results = face_recognition.compare_faces(unknown_encodings, known_encoding)\n",
    "    person_detected=['Verkha' if x else 'Unknown' for x in results]\n",
    "    sub_lists = [person_detected[i: i+frame_rate] for i in range(0, len(person_detected), frame_rate)]\n",
    "    person_count_per_sec=[sub_list.count('Unknown') for sub_list in sub_lists]\n",
    "    \n",
    "    return [1 if i>=25 else 0 for i in person_count_per_sec]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames Rate: 30.105092 frames/second\n",
      "Frame Count: 491 frames\n",
      "Video Duration: 16 seconds\n",
      "width,height : 1280 X 720\n"
     ]
    }
   ],
   "source": [
    "analize_video('/home/ubuntu/videos/interview_videos/face_identify.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames=get_frames('/home/ubuntu/videos/interview_videos/face_identify.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_person=check_identity(all_frames,'/home/ubuntu/videos/interview_videos/verkha.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-face detection using face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiface_detect(frames, frame_rate=30):\n",
    "    num_faces = [len(face_recognition.face_locations(i)) for i in frames]\n",
    "    faces_per_second = [num_faces[i: i+frame_rate] for i in range(0, len(num_faces), frame_rate)]\n",
    "    person_count = [len([x for x in per_second if x > 1]) for per_second in faces_per_second]\n",
    "    return [1 if i > 25 else 0 for i in person_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames Rate: 30.108317 frames/second\n",
      "Frame Count: 410 frames\n",
      "Video Duration: 13 seconds\n",
      "width,height : 1280 X 720\n"
     ]
    }
   ],
   "source": [
    "analize_video('/home/ubuntu/videos/interview_videos/two_persons.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=get_frames('/home/ubuntu/videos/interview_videos/two_persons.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_person=multiface_detect(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video_writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect(frame):\n",
    "    face_locations = face_recognition.face_locations(frame) \n",
    "    cnt=str(len(face_locations))\n",
    "    for face_location in face_locations: ## Not necessary\n",
    "        (t,r,b,l)=face_location\n",
    "        frame = cv2.rectangle(frame, (l, t), (r, b), (0,0,255), 2)\n",
    "        cv2.putText(frame, 'persons detected: '+cnt, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), lineType=cv2.LINE_AA,thickness=2)        \n",
    "    return frame\n",
    "\n",
    "def write_video(frames):   \n",
    "    height, width = frames[0].shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')        #frame rate         \n",
    "    out = cv2.VideoWriter('Two_faces.avi',fourcc, 30.0, (width, height))\n",
    "    for frame in frames:\n",
    "        out.write(frame)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=get_frames('/home/ubuntu/videos/interview_videos/two_persons.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_frame=[face_detect(frame) for frame in frames]\n",
    "write_video(processed_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-object detection using cvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvlib as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_frames(video_path):  \n",
    "    cap= cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()  \n",
    "        if ret==True:\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    return frames \n",
    "\n",
    "def detect_faces(frame):\n",
    "    face_locations, label, conf = cv.detect_common_objects(frame) \n",
    "    cnt=str(len(face_locations))    \n",
    "    for face_location in face_locations:\n",
    "        (sx,sy,ex,ey)=face_location\n",
    "        frame = cv2.rectangle(frame, (sx, sy), (ex, ey), (0,0,255), 2)\n",
    "        cv2.putText(frame, 'persons detected: '+cnt, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), lineType=cv2.LINE_AA,thickness=2)       \n",
    "    return frame\n",
    "\n",
    "def write_video(frames):   \n",
    "    height, width = frames[0].shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')        #frame rate         \n",
    "    out = cv2.VideoWriter('multi_obj_detection.avi',fourcc, 30.0, (width, height))\n",
    "    for frame in frames:\n",
    "        out.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=get_all_frames('/home/ubuntu/videos/interview_videos/two_persons.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_with_detected_faces=[detect_faces(frame) for frame in frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames_with_detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_video(frames_with_detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_env",
   "language": "python",
   "name": "video_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
